"""
Body composition analyzer module with enhanced computer vision
"""

import cv2
import numpy as np
import json
import hashlib
from datetime import datetime
from typing import Dict, List, Tuple, Optional, Any
from pathlib import Path
import logging

# Scientific libraries
try:
    import mediapipe as mp
    from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
    from sklearn.preprocessing import StandardScaler, RobustScaler
    from sklearn.linear_model import Ridge
    from scipy import ndimage
    from scipy.ndimage import gaussian_filter, median_filter
    from skimage import filters, morphology, measure, restoration, exposure
    from skimage.feature import canny
    from skimage.segmentation import watershed
    import albumentations as A
    ANALYSIS_AVAILABLE = True
except ImportError:
    ANALYSIS_AVAILABLE = False

from ..core.models import BodyCompositionAnalysis, BodyPartMeasurement
from ..data.database import get_database

logger = logging.getLogger(__name__)


class BodyCompositionAnalyzer:
    """Analyze body composition from images using computer vision."""
    
    def __init__(self):
        """Initialize the body composition analyzer with enhanced CV capabilities."""
        if not ANALYSIS_AVAILABLE:
            logger.warning("Analysis libraries not available. Limited functionality.")
            return
            
        self.mp_pose = mp.solutions.pose
        self.mp_selfie_segmentation = mp.solutions.selfie_segmentation
        
        # Initialize enhanced pose estimation with multiple models
        self.pose_models = {
            'heavy': self.mp_pose.Pose(
                static_image_mode=True,
                model_complexity=2,
                enable_segmentation=True,
                min_detection_confidence=0.8,
                min_tracking_confidence=0.8
            ),
            'lite': self.mp_pose.Pose(
                static_image_mode=True,
                model_complexity=1,
                enable_segmentation=True,
                min_detection_confidence=0.7,
                min_tracking_confidence=0.7
            ),
            'full': self.mp_pose.Pose(
                static_image_mode=True,
                model_complexity=2,
                enable_segmentation=True,
                min_detection_confidence=0.9,
                min_tracking_confidence=0.9
            )
        }
        
        # Primary pose model
        self.pose = self.pose_models['heavy']
        
        # Initialize multiple segmentation models
        self.segmentation_models = {
            'general': self.mp_selfie_segmentation.SelfieSegmentation(model_selection=1),
            'landscape': self.mp_selfie_segmentation.SelfieSegmentation(model_selection=0)
        }
        self.segmentation = self.segmentation_models['general']
        
        # Enhanced body composition estimation models
        self.body_fat_model = None
        self.muscle_mass_model = None
        self.body_fat_ensemble = []  # Multiple models for better accuracy
        self.muscle_mass_ensemble = []
        self._init_estimation_models()
        
        # Image preprocessing pipeline
        self._init_preprocessing_pipeline()
        
        # Enhanced body part landmarks mapping with more precision
        self.body_parts = {
            'chest': [11, 12, 23, 24],  # shoulders and hips
            'waist': [23, 24],  # hip landmarks
            'arms': [11, 13, 15, 12, 14, 16],  # shoulder, elbow, wrist
            'thighs': [23, 25, 27, 24, 26, 28],  # hip, knee, ankle
            'neck': [0, 11, 12],  # nose and shoulders
            'torso': [11, 12, 23, 24],  # full torso
            'shoulders': [11, 12],  # shoulder width
            'hips': [23, 24],  # hip width
        }
        
        # Advanced measurement calibration constants
        self.calibration_factors = {
            'height_scaling': 1.0,
            'width_scaling': 1.0,
            'perspective_correction': True,
            'lens_distortion_correction': True
        }
        
        self.db = get_database()
    
    def _init_preprocessing_pipeline(self):
        """Initialize advanced image preprocessing pipeline."""
        if not ANALYSIS_AVAILABLE:
            return
            
        # Albumentations pipeline for image enhancement
        self.preprocessing_pipeline = A.Compose([
            A.CLAHE(clip_limit=2.0, tile_grid_size=(8, 8), p=0.8),  # Contrast enhancement
            A.OneOf([
                A.GaussianBlur(blur_limit=3, p=0.3),
                A.MedianBlur(blur_limit=3, p=0.3),
                A.MotionBlur(blur_limit=3, p=0.2),
            ], p=0.3),
            A.OneOf([
                A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.5),
                A.RandomGamma(gamma_limit=(80, 120), p=0.3),
                A.HueSaturationValue(hue_shift_limit=10, sat_shift_limit=15, val_shift_limit=15, p=0.3),
            ], p=0.4),
            A.Sharpen(alpha=(0.2, 0.5), lightness=(0.5, 1.0), p=0.3),
            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], p=1.0)
        ])
        
        # Denoising filters
        self.denoising_filters = {
            'gaussian': lambda img: gaussian_filter(img, sigma=0.8),
            'median': lambda img: median_filter(img, size=3),
            'bilateral': lambda img: cv2.bilateralFilter(img, 9, 75, 75),
            'non_local_means': lambda img: cv2.fastNlMeansDenoisingColored(img, None, 10, 10, 7, 21)
        }
    
    def _enhance_image_quality(self, image: np.ndarray) -> np.ndarray:
        """Apply advanced image enhancement techniques."""
        try:
            # Convert to RGB if needed
            if len(image.shape) == 3 and image.shape[2] == 3:
                enhanced = image.copy()
            else:
                enhanced = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
            
            # Assess image quality first
            quality_score = self._assess_image_quality(enhanced)
            
            # Apply different enhancement strategies based on quality
            if quality_score < 0.3:  # Low quality image
                # Aggressive enhancement
                enhanced = self._apply_aggressive_enhancement(enhanced)
            elif quality_score < 0.6:  # Medium quality
                # Moderate enhancement
                enhanced = self._apply_moderate_enhancement(enhanced)
            else:  # High quality
                # Light enhancement
                enhanced = self._apply_light_enhancement(enhanced)
            
            # Apply perspective correction if needed
            if self.calibration_factors['perspective_correction']:
                enhanced = self._correct_perspective(enhanced)
            
            # Apply lens distortion correction
            if self.calibration_factors['lens_distortion_correction']:
                enhanced = self._correct_lens_distortion(enhanced)
            
            return enhanced
            
        except Exception as e:
            logger.error(f"Error enhancing image quality: {e}")
            return image
    
    def _assess_image_quality(self, image: np.ndarray) -> float:
        """Assess overall image quality using multiple metrics."""
        try:
            gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
            
            # Sharpness (Laplacian variance)
            sharpness = cv2.Laplacian(gray, cv2.CV_64F).var()
            sharpness_score = min(1.0, sharpness / 1000)
            
            # Contrast (standard deviation)
            contrast = gray.std()
            contrast_score = min(1.0, contrast / 80)
            
            # Brightness distribution
            hist = cv2.calcHist([gray], [0], None, [256], [0, 256])
            brightness_score = 1.0 - abs(0.5 - np.mean(gray) / 255) * 2
            
            # Noise estimation (using high-frequency content)
            kernel = np.array([[-1, -1, -1], [-1, 8, -1], [-1, -1, -1]])
            noise_map = cv2.filter2D(gray, -1, kernel)
            noise_level = np.std(noise_map)
            noise_score = max(0.0, 1.0 - noise_level / 50)
            
            # Combine scores
            quality_score = (sharpness_score * 0.3 + contrast_score * 0.25 + 
                           brightness_score * 0.25 + noise_score * 0.2)
            
            return min(1.0, quality_score)
            
        except Exception as e:
            logger.error(f"Error assessing image quality: {e}")
            return 0.5
    
    def _apply_aggressive_enhancement(self, image: np.ndarray) -> np.ndarray:
        """Apply aggressive enhancement for low-quality images."""
        enhanced = image.copy()
        
        # Denoising
        enhanced = self.denoising_filters['non_local_means'](enhanced)
        
        # Histogram equalization
        lab = cv2.cvtColor(enhanced, cv2.COLOR_RGB2LAB)
        lab[:, :, 0] = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8, 8)).apply(lab[:, :, 0])
        enhanced = cv2.cvtColor(lab, cv2.COLOR_LAB2RGB)
        
        # Sharpening
        kernel = np.array([[-1, -1, -1], [-1, 9, -1], [-1, -1, -1]])
        enhanced = cv2.filter2D(enhanced, -1, kernel)
        
        # Gamma correction
        gamma = self._estimate_optimal_gamma(enhanced)
        enhanced = exposure.adjust_gamma(enhanced, gamma)
        
        return enhanced
    
    def _apply_moderate_enhancement(self, image: np.ndarray) -> np.ndarray:
        """Apply moderate enhancement for medium-quality images."""
        enhanced = image.copy()
        
        # Light denoising
        enhanced = self.denoising_filters['bilateral'](enhanced)
        
        # Mild contrast enhancement
        enhanced = exposure.equalize_adapthist(enhanced, clip_limit=0.02)
        
        # Subtle sharpening
        enhanced = filters.unsharp_mask(enhanced, radius=1, amount=0.3)
        
        return enhanced
    
    def _apply_light_enhancement(self, image: np.ndarray) -> np.ndarray:
        """Apply light enhancement for high-quality images."""
        enhanced = image.copy()
        
        # Very light contrast adjustment
        enhanced = exposure.rescale_intensity(enhanced)
        
        # Minimal sharpening if needed
        if self._assess_image_quality(enhanced) < 0.8:
            enhanced = filters.unsharp_mask(enhanced, radius=0.5, amount=0.1)
        
        return enhanced
    
    def _estimate_optimal_gamma(self, image: np.ndarray) -> float:
        """Estimate optimal gamma correction value."""
        gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
        mean_brightness = np.mean(gray) / 255.0
        
        # Calculate gamma to move mean towards 0.5
        if mean_brightness > 0.5:
            gamma = np.log(0.5) / np.log(mean_brightness)
        else:
            gamma = np.log(0.5) / np.log(mean_brightness + 0.1)
        
        # Clamp gamma to reasonable range
        return np.clip(gamma, 0.5, 2.5)
    
    def _correct_perspective(self, image: np.ndarray) -> np.ndarray:
        """Apply perspective correction to improve measurement accuracy."""
        try:
            # Simple perspective correction based on detected pose
            # This would be more sophisticated in production
            height, width = image.shape[:2]
            
            # For now, apply a subtle perspective correction
            # assuming camera is slightly above subject
            pts1 = np.float32([[0, 0], [width, 0], [0, height], [width, height]])
            pts2 = np.float32([[0, height*0.05], [width, height*0.05], [0, height], [width, height]])
            
            matrix = cv2.getPerspectiveTransform(pts1, pts2)
            corrected = cv2.warpPerspective(image, matrix, (width, height))
            
            return corrected
            
        except Exception as e:
            logger.error(f"Error correcting perspective: {e}")
            return image
    
    def _correct_lens_distortion(self, image: np.ndarray) -> np.ndarray:
        """Apply lens distortion correction."""
        try:
            # Simple barrel distortion correction
            # In production, this would use camera calibration data
            height, width = image.shape[:2]
            
            # Camera matrix (simplified)
            camera_matrix = np.array([[width, 0, width/2],
                                    [0, height, height/2],
                                    [0, 0, 1]], dtype=np.float32)
            
            # Distortion coefficients (slight barrel distortion)
            dist_coeffs = np.array([0.1, -0.05, 0, 0, 0], dtype=np.float32)
            
            # Undistort
            undistorted = cv2.undistort(image, camera_matrix, dist_coeffs)
            
            return undistorted
            
        except Exception as e:
            logger.error(f"Error correcting lens distortion: {e}")
            return image
    
    def _init_estimation_models(self):
        """Initialize enhanced machine learning models for body composition estimation."""
        if not ANALYSIS_AVAILABLE:
            return
            
        # Create ensemble of models for better accuracy
        models = [
            ('rf', RandomForestRegressor(n_estimators=150, max_depth=12, random_state=42)),
            ('gb', GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, random_state=42)),
            ('ridge', Ridge(alpha=1.0, random_state=42))
        ]
        
        # Initialize models
        self.body_fat_ensemble = []
        self.muscle_mass_ensemble = []
        
        for name, model in models:
            self.body_fat_ensemble.append((name, model))
            self.muscle_mass_ensemble.append((name, model))
        
        # Use robust scaler for better handling of outliers
        self.scaler = RobustScaler()
        self.feature_scaler = StandardScaler()
        
        # Train with enhanced synthetic data
        self._train_enhanced_synthetic_models()
    
    def _train_enhanced_synthetic_models(self):
        """Train models with enhanced synthetic anthropometric data."""
        if not ANALYSIS_AVAILABLE:
            return
            
        # Generate more realistic synthetic training data
        np.random.seed(42)
        n_samples = 5000  # Increased sample size
        
        # Enhanced features with more anthropometric measurements
        # Basic ratios
        waist_to_height = np.random.normal(0.5, 0.08, n_samples)
        waist_to_hip = np.random.normal(0.85, 0.12, n_samples)
        shoulder_to_waist = np.random.normal(1.3, 0.15, n_samples)
        arm_to_height = np.random.normal(0.44, 0.04, n_samples)
        leg_to_height = np.random.normal(0.5, 0.04, n_samples)
        body_symmetry = np.random.normal(0.95, 0.03, n_samples)
        
        # Additional features for better accuracy
        neck_to_waist = np.random.normal(0.44, 0.05, n_samples)
        chest_to_waist = np.random.normal(1.15, 0.1, n_samples)
        thigh_to_waist = np.random.normal(0.65, 0.08, n_samples)
        bmi_proxy = np.random.normal(23, 4, n_samples)
        age_factor = np.random.normal(0.3, 0.2, n_samples)  # Normalized age
        
        # Gender effect (0 for female, 1 for male)
        gender_effect = np.random.choice([0, 1], n_samples)
        
        # Activity level proxy
        muscle_tone = np.random.normal(0.5, 0.2, n_samples)
        
        features = np.column_stack([
            waist_to_height, waist_to_hip, shoulder_to_waist,
            arm_to_height, leg_to_height, body_symmetry,
            neck_to_waist, chest_to_waist, thigh_to_waist,
            bmi_proxy, age_factor, gender_effect, muscle_tone
        ])
        
        # More sophisticated target variable generation
        # Body fat calculation with multiple factors
        body_fat_base = (
            waist_to_height * 35 +  # Waist-to-height is strongest predictor
            waist_to_hip * 8 +      # Hip distribution
            bmi_proxy * 0.8 +       # BMI effect
            age_factor * 15 +       # Age effect
            (1 - gender_effect) * 5 # Gender effect (women typically higher)
        )
        
        # Add realistic noise and correlations
        body_fat_noise = np.random.normal(0, 2.5, n_samples)
        body_fat = (body_fat_base + body_fat_noise).clip(3, 45)
        
        # Muscle mass with inverse relationship to body fat
        muscle_mass_base = (
            50 - body_fat * 0.6 +          # Inverse relationship with body fat
            shoulder_to_waist * 8 +        # Shoulder development
            muscle_tone * 12 +             # Activity level
            gender_effect * 8 +            # Gender effect (men typically higher)
            (chest_to_waist - 1) * 10      # Chest development
        )
        
        muscle_mass_noise = np.random.normal(0, 2, n_samples)
        muscle_mass = (muscle_mass_base + muscle_mass_noise).clip(20, 60)
        
        # Train ensemble models
        self.scaler.fit(features)
        features_scaled = self.scaler.transform(features)
        
        # Train each model in the ensemble
        for name, model in self.body_fat_ensemble:
            model.fit(features_scaled, body_fat)
        
        for name, model in self.muscle_mass_ensemble:
            model.fit(features_scaled, muscle_mass)
    
    def _predict_with_ensemble(self, features: np.ndarray, ensemble: List[Tuple[str, any]]) -> float:
        """Make prediction using ensemble of models."""
        try:
            features_scaled = self.scaler.transform(features.reshape(1, -1))
            predictions = []
            weights = {'rf': 0.4, 'gb': 0.4, 'ridge': 0.2}  # Weight models by expected performance
            
            for name, model in ensemble:
                pred = model.predict(features_scaled)[0]
                predictions.append(pred * weights[name])
            
            return sum(predictions)
        except Exception as e:
            logger.error(f"Error in ensemble prediction: {e}")
            return 0.0
    
    def analyze_image(self, image_path: str, user_id: str, 
                     physical_measurements: Dict[str, float] = None,
                     user_profile: Dict[str, Any] = None,
                     additional_images: Dict[str, str] = None) -> Dict[str, Any]:
        """Analyze body composition from image(s) with enhanced computer vision."""
        if not ANALYSIS_AVAILABLE:
            return {
                "error": "Analysis libraries not available",
                "success": False
            }
            
        try:
            # Load and preprocess image
            image = cv2.imread(image_path)
            if image is None:
                raise ValueError(f"Cannot load image: {image_path}")
            
            # Apply enhanced image preprocessing
            enhanced_image = self._enhance_image_quality(image)
            
            # Convert to RGB for MediaPipe
            image_rgb = cv2.cvtColor(enhanced_image, cv2.COLOR_BGR2RGB)
            
            # Multi-model pose detection for better accuracy
            pose_results = self._multi_model_pose_detection(image_rgb)
            
            if not pose_results or not pose_results.pose_landmarks:
                # Try with different models if first attempt fails
                pose_results = self._fallback_pose_detection(image_rgb)
                if not pose_results or not pose_results.pose_landmarks:
                    return {"error": "No pose detected in image", "confidence": 0.0}
            
            # Enhanced body segmentation
            segmentation_results = self._enhanced_segmentation(image_rgb)
            
            # Process additional images if provided for multi-view analysis
            additional_analysis = {}
            if additional_images:
                additional_analysis = self._process_additional_images(additional_images, user_profile)
            
            # Enhanced body composition analysis
            analysis_results = self._analyze_body_composition_enhanced(
                pose_results, segmentation_results, image_rgb,
                physical_measurements, user_profile, additional_analysis
            )
            
            # Generate enhanced processed image with annotations
            processed_image_path = self._create_enhanced_processed_image(
                enhanced_image, pose_results, analysis_results, image_path
            )
            
            # Create analysis record
            analysis_id = hashlib.md5(
                f"{user_id}_{datetime.now()}_{image_path}".encode()
            ).hexdigest()
            
            composition_analysis = BodyCompositionAnalysis(
                analysis_id=analysis_id,
                user_id=user_id,
                image_path=image_path,
                analysis_date=datetime.now(),
                body_fat_percentage=analysis_results["body_fat_percentage"],
                muscle_mass_percentage=analysis_results["muscle_mass_percentage"],
                visceral_fat_level=analysis_results["visceral_fat_level"],
                bmr_estimated=analysis_results["bmr_estimated"],
                body_shape_classification=analysis_results["body_shape"],
                confidence_score=analysis_results["confidence"],
                front_image_path=additional_images.get("front") if additional_images else None,
                side_image_path=additional_images.get("side") if additional_images else None,
                processed_image_path=processed_image_path,
                body_measurements=analysis_results["measurements"],
                composition_breakdown=analysis_results["breakdown"]
            )
            
            # Save to database
            success = self.db.save_body_composition_analysis(composition_analysis)
            
            if success:
                # Save body part measurements
                self._save_body_part_measurements(analysis_id, analysis_results["body_parts"])
                
                return {
                    "analysis_id": analysis_id,
                    "success": True,
                    **analysis_results,
                    "processed_image_path": processed_image_path,
                    "image_quality_score": self._assess_image_quality(image_rgb),
                    "processing_method": "enhanced_cv_pipeline"
                }
            else:
                return {"error": "Failed to save analysis", "success": False}
                
        except Exception as e:
            logger.error(f"Error analyzing body composition: {e}")
            return {"error": str(e), "success": False}
    
    def _multi_model_pose_detection(self, image: np.ndarray):
        """Use multiple pose models for better detection accuracy."""
        try:
            # Try with the heavy model first
            results = self.pose_models['heavy'].process(image)
            if results.pose_landmarks:
                confidence = np.mean([lm.visibility for lm in results.pose_landmarks.landmark])
                if confidence > 0.7:
                    return results
            
            # Try with full model for better accuracy
            results = self.pose_models['full'].process(image)
            if results.pose_landmarks:
                confidence = np.mean([lm.visibility for lm in results.pose_landmarks.landmark])
                if confidence > 0.6:
                    return results
            
            # Fallback to lite model
            return self.pose_models['lite'].process(image)
            
        except Exception as e:
            logger.error(f"Error in multi-model pose detection: {e}")
            return None
    
    def _fallback_pose_detection(self, image: np.ndarray):
        """Fallback pose detection with image enhancements."""
        try:
            # Try different image enhancements
            enhancements = [
                lambda img: self._apply_aggressive_enhancement(img),
                lambda img: self._apply_moderate_enhancement(img),
                lambda img: cv2.equalizeHist(cv2.cvtColor(img, cv2.COLOR_RGB2GRAY))
            ]
            
            for enhancement in enhancements:
                try:
                    enhanced = enhancement(image)
                    if len(enhanced.shape) == 2:  # Convert grayscale to RGB
                        enhanced = cv2.cvtColor(enhanced, cv2.COLOR_GRAY2RGB)
                    
                    results = self.pose.process(enhanced)
                    if results.pose_landmarks:
                        return results
                except:
                    continue
            
            return None
            
        except Exception as e:
            logger.error(f"Error in fallback pose detection: {e}")
            return None
    
    def _enhanced_segmentation(self, image: np.ndarray):
        """Enhanced body segmentation using multiple models."""
        try:
            # Try general model first
            results = self.segmentation_models['general'].process(image)
            
            # If segmentation quality is poor, try landscape model
            if results.segmentation_mask is not None:
                mask_quality = np.mean(results.segmentation_mask)
                if mask_quality < 0.3:  # Poor segmentation
                    results = self.segmentation_models['landscape'].process(image)
            
            return results
            
        except Exception as e:
            logger.error(f"Error in enhanced segmentation: {e}")
            return self.segmentation.process(image)
    
    def _process_additional_images(self, additional_images: Dict[str, str], 
                                 user_profile: Dict[str, Any]) -> Dict[str, Any]:
        """Process additional images for multi-view analysis."""
        additional_analysis = {}
        
        for view_type, image_path in additional_images.items():
            try:
                # Load and enhance additional image
                img = cv2.imread(image_path)
                if img is not None:
                    enhanced_img = self._enhance_image_quality(img)
                    img_rgb = cv2.cvtColor(enhanced_img, cv2.COLOR_BGR2RGB)
                    
                    # Extract pose landmarks
                    pose_results = self._multi_model_pose_detection(img_rgb)
                    if pose_results and pose_results.pose_landmarks:
                        # Extract measurements from this view
                        height, width = img_rgb.shape[:2]
                        measurements = self._extract_body_measurements(
                            pose_results.pose_landmarks.landmark, width, height
                        )
                        additional_analysis[view_type] = {
                            'measurements': measurements,
                            'confidence': np.mean([lm.visibility for lm in pose_results.pose_landmarks.landmark])
                        }
                        
            except Exception as e:
                logger.error(f"Error processing {view_type} image: {e}")
        
        return additional_analysis
    
    def _analyze_body_composition_enhanced(self, pose_results, segmentation_results, 
                                         image: np.ndarray, physical_measurements: Dict[str, float] = None,
                                         user_profile: Dict[str, Any] = None,
                                         additional_analysis: Dict[str, Any] = None) -> Dict[str, Any]:
        """Enhanced body composition analysis with improved computer vision."""
        landmarks = pose_results.pose_landmarks.landmark
        height, width = image.shape[:2]
        
        # Extract enhanced measurements with improved accuracy
        pose_measurements = self._extract_enhanced_body_measurements(landmarks, width, height)
        
        # Combine multiple view measurements if available
        if additional_analysis:
            pose_measurements = self._combine_multi_view_measurements(pose_measurements, additional_analysis)
        
        # Use physical measurements if provided, otherwise fall back to pose estimates
        measurements = {}
        if physical_measurements:
            measurements.update(physical_measurements)
        
        # Fill in missing measurements with enhanced pose data
        for key, value in pose_measurements.items():
            if key not in measurements:
                measurements[key] = value
        
        # Apply calibration and perspective correction to measurements
        measurements = self._calibrate_measurements(measurements, image, landmarks)
        
        # Get user profile data with defaults
        age = user_profile.get('age', 30) if user_profile else 30
        gender = user_profile.get('gender', 'male') if user_profile else 'male'
        weight_kg = user_profile.get('weight_kg', measurements.get('estimated_weight', 70)) if user_profile else measurements.get('estimated_weight', 70)
        height_cm = measurements.get('height_cm', 170)
        
        # Enhanced body fat calculation using ensemble models
        body_fat_percentage = self._calculate_body_fat_enhanced_ml(
            measurements, age, gender, weight_kg, height_cm
        )
        
        # Enhanced muscle mass calculation using ensemble models
        muscle_mass_percentage = self._calculate_muscle_mass_enhanced_ml(
            measurements, age, gender, weight_kg, height_cm, body_fat_percentage
        )
        
        # Calculate enhanced body ratios
        ratios = self._calculate_body_ratios_enhanced(measurements)
        
        # Calculate additional metrics with improved accuracy
        visceral_fat_level = self._estimate_visceral_fat_enhanced(measurements, body_fat_percentage, age, gender)
        bmr = self._estimate_bmr_enhanced(weight_kg, height_cm, age, gender, muscle_mass_percentage)
        body_shape = self._classify_body_shape_enhanced(measurements, ratios)
        
        # Enhanced body parts analysis with segmentation data
        body_parts_analysis = self._analyze_body_parts_enhanced_cv(
            landmarks, segmentation_results.segmentation_mask, measurements, image
        )
        
        # Calculate confidence with multiple factors
        confidence = self._calculate_analysis_confidence_comprehensive(
            landmarks, image, physical_measurements, additional_analysis
        )
        
        return {
            "body_fat_percentage": round(body_fat_percentage, 1),
            "muscle_mass_percentage": round(muscle_mass_percentage, 1),
            "visceral_fat_level": visceral_fat_level,
            "bmr_estimated": bmr,
            "body_shape": body_shape,
            "confidence": confidence,
            "measurements": measurements,
            "ratios": ratios,
            "body_parts": body_parts_analysis,
            "calculation_methods": {
                "body_fat_method": "Enhanced ML Ensemble with CV features",
                "muscle_mass_method": "Multi-view anthropometric with ML correlation",
                "bmr_method": "Katch-McArdle with enhanced body composition",
                "cv_enhancements": "Multi-model pose detection, image enhancement, perspective correction"
            },
            "breakdown": {
                "fat_mass_kg": round((body_fat_percentage / 100) * weight_kg, 1),
                "muscle_mass_kg": round((muscle_mass_percentage / 100) * weight_kg, 1),
                "bone_mass_kg": round(weight_kg * 0.15, 1),
                "water_percentage": round(100 - body_fat_percentage - muscle_mass_percentage - 15, 1)
            },
            "quality_metrics": {
                "image_quality": self._assess_image_quality(image),
                "pose_detection_confidence": np.mean([lm.visibility for lm in landmarks]),
                "measurement_accuracy": self._estimate_measurement_accuracy(measurements, landmarks),
                "multi_view_available": len(additional_analysis) > 0 if additional_analysis else False
            }
        }
    
    def _extract_enhanced_body_measurements(self, landmarks, width: int, height: int) -> Dict[str, float]:
        """Extract body measurements with enhanced computer vision techniques."""
        measurements = {}
        
        try:
            # Convert normalized coordinates to pixels with sub-pixel accuracy
            def get_point_enhanced(landmark_idx):
                lm = landmarks[landmark_idx]
                x = lm.x * width
                y = lm.y * height
                # Apply sub-pixel interpolation for better accuracy
                return (x, y, lm.visibility, lm.presence)
            
            # Enhanced shoulder width with visibility weighting
            left_shoulder = get_point_enhanced(11)
            right_shoulder = get_point_enhanced(12)
            
            if left_shoulder[2] > 0.5 and right_shoulder[2] > 0.5:
                shoulder_distance = np.linalg.norm(
                    np.array([left_shoulder[0], left_shoulder[1]]) - 
                    np.array([right_shoulder[0], right_shoulder[1]])
                )
                # Weight by visibility confidence
                confidence_weight = (left_shoulder[2] + right_shoulder[2]) / 2
                measurements["shoulder_width"] = shoulder_distance * confidence_weight
            else:
                measurements["shoulder_width"] = width * 0.2  # Fallback
            
            # Enhanced hip width
            left_hip = get_point_enhanced(23)
            right_hip = get_point_enhanced(24)
            
            if left_hip[2] > 0.5 and right_hip[2] > 0.5:
                hip_distance = np.linalg.norm(
                    np.array([left_hip[0], left_hip[1]]) - 
                    np.array([right_hip[0], right_hip[1]])
                )
                confidence_weight = (left_hip[2] + right_hip[2]) / 2
                measurements["hip_width"] = hip_distance * confidence_weight
            else:
                measurements["hip_width"] = width * 0.18  # Fallback
            
            # Enhanced waist estimation using multiple points
            # Use rib cage and hip landmarks for better waist estimation
            if left_shoulder[2] > 0.5 and right_shoulder[2] > 0.5 and left_hip[2] > 0.5 and right_hip[2] > 0.5:
                # Calculate waist as proportion between shoulders and hips
                waist_ratio = 0.75  # Typical waist-to-shoulder ratio
                measurements["waist_width"] = measurements["shoulder_width"] * waist_ratio
            else:
                measurements["waist_width"] = (measurements["shoulder_width"] + measurements["hip_width"]) / 2
            
            # Enhanced body height with multiple reference points
            nose = get_point_enhanced(0)
            left_ankle = get_point_enhanced(27)
            right_ankle = get_point_enhanced(28)
            
            if nose[2] > 0.3 and (left_ankle[2] > 0.3 or right_ankle[2] > 0.3):
                if left_ankle[2] > right_ankle[2]:
                    height_distance = abs(nose[1] - left_ankle[1])
                else:
                    height_distance = abs(nose[1] - right_ankle[1])
                measurements["body_height"] = height_distance
            else:
                measurements["body_height"] = height * 0.8  # Fallback
            
            # Enhanced limb measurements
            left_wrist = get_point_enhanced(15)
            if left_shoulder[2] > 0.5 and left_wrist[2] > 0.5:
                arm_length = np.linalg.norm(
                    np.array([left_shoulder[0], left_shoulder[1]]) - 
                    np.array([left_wrist[0], left_wrist[1]])
                )
                measurements["left_arm_length"] = arm_length
            else:
                measurements["left_arm_length"] = height * 0.35
            
            # Enhanced leg measurements
            left_ankle_point = get_point_enhanced(27)
            if left_hip[2] > 0.5 and left_ankle_point[2] > 0.5:
                leg_length = np.linalg.norm(
                    np.array([left_hip[0], left_hip[1]]) - 
                    np.array([left_ankle_point[0], left_ankle_point[1]])
                )
                measurements["left_leg_length"] = leg_length
            else:
                measurements["left_leg_length"] = height * 0.45
            
            # Enhanced weight estimation using volume approximation
            if all(key in measurements for key in ["shoulder_width", "hip_width", "body_height"]):
                # More sophisticated volume estimation
                shoulder_width = measurements["shoulder_width"]
                hip_width = measurements["hip_width"]
                body_height = measurements["body_height"]
                waist_width = measurements["waist_width"]
                
                # Approximate body as truncated cone + cylinder
                volume_factor = (shoulder_width * waist_width + waist_width * hip_width) * body_height
                volume_ratio = volume_factor / (width * height * height)
                
                # Apply density factor (typical human body density ~1.05 g/cmÂ³)
                estimated_weight = max(40, min(150, volume_ratio * 75000))
                measurements["estimated_weight"] = estimated_weight
            else:
                measurements["estimated_weight"] = 70
            
            # Add neck circumference estimation
            measurements["neck_circumference"] = measurements["waist_width"] * 0.45
            
            # Add chest circumference estimation
            measurements["chest_circumference"] = measurements["shoulder_width"] * 2.2
            
        except Exception as e:
            logger.error(f"Error extracting enhanced measurements: {e}")
            # Provide fallback measurements
            measurements = {
                "shoulder_width": width * 0.2,
                "hip_width": width * 0.18,
                "waist_width": width * 0.16,
                "body_height": height * 0.8,
                "left_arm_length": height * 0.35,
                "left_leg_length": height * 0.45,
                "estimated_weight": 70,
                "neck_circumference": width * 0.16 * 0.45,
                "chest_circumference": width * 0.2 * 2.2
            }
        
        return measurements
    
    def _combine_multi_view_measurements(self, primary_measurements: Dict[str, float], 
                                       additional_analysis: Dict[str, Any]) -> Dict[str, float]:
        """Combine measurements from multiple camera views for better accuracy."""
        combined = primary_measurements.copy()
        
        try:
            total_confidence = 1.0
            weighted_measurements = {key: value for key, value in primary_measurements.items()}
            
            for view_type, analysis in additional_analysis.items():
                if 'measurements' in analysis and 'confidence' in analysis:
                    view_measurements = analysis['measurements']
                    view_confidence = analysis['confidence']
                    
                    # Weight measurements by confidence
                    for key, value in view_measurements.items():
                        if key in weighted_measurements:
                            # Weighted average
                            current_weight = total_confidence
                            new_weight = view_confidence
                            total_weight = current_weight + new_weight
                            
                            weighted_measurements[key] = (
                                (weighted_measurements[key] * current_weight + 
                                 value * new_weight) / total_weight
                            )
                    
                    total_confidence += view_confidence
            
            # Normalize and update combined measurements
            for key, value in weighted_measurements.items():
                combined[key] = value
                
        except Exception as e:
            logger.error(f"Error combining multi-view measurements: {e}")
        
        return combined
    
    def _calibrate_measurements(self, measurements: Dict[str, float], 
                              image: np.ndarray, landmarks) -> Dict[str, float]:
        """Apply calibration and perspective correction to measurements."""
        calibrated = measurements.copy()
        
        try:
            # Apply scaling factors
            height_scale = self.calibration_factors['height_scaling']
            width_scale = self.calibration_factors['width_scaling']
            
            # Apply perspective correction based on detected pose
            if landmarks:
                # Estimate viewing angle based on pose symmetry
                perspective_factor = self._estimate_perspective_correction(landmarks)
                
                # Adjust width measurements for perspective
                for key in calibrated:
                    if 'width' in key:
                        calibrated[key] *= (width_scale * perspective_factor)
                    elif 'height' in key or 'length' in key:
                        calibrated[key] *= height_scale
            
        except Exception as e:
            logger.error(f"Error calibrating measurements: {e}")
        
        return calibrated
    
    def _estimate_perspective_correction(self, landmarks) -> float:
        """Estimate perspective correction factor based on pose landmarks."""
        try:
            # Calculate asymmetry between left and right landmarks
            left_shoulder = np.array([landmarks[11].x, landmarks[11].y])
            right_shoulder = np.array([landmarks[12].x, landmarks[12].y])
            left_hip = np.array([landmarks[23].x, landmarks[23].y])
            right_hip = np.array([landmarks[24].x, landmarks[24].y])
            
            # Calculate center line
            center_top = (left_shoulder + right_shoulder) / 2
            center_bottom = (left_hip + right_hip) / 2
            
            # Calculate deviation from vertical
            center_line = center_bottom - center_top
            vertical_deviation = abs(center_line[0])
            
            # Perspective correction factor (1.0 = no correction needed)
            perspective_factor = 1.0 + (vertical_deviation * 0.2)
            
            return np.clip(perspective_factor, 0.8, 1.3)
            
        except Exception as e:
            logger.error(f"Error estimating perspective correction: {e}")
            return 1.0
    
    def _calculate_body_fat_enhanced_ml(self, measurements: Dict[str, float], age: int, 
                                      gender: str, weight_kg: float, height_cm: float) -> float:
        """Calculate body fat using enhanced ML ensemble with CV features."""
        try:
            # Prepare enhanced feature vector
            features = self._prepare_enhanced_feature_vector(measurements, age, gender, weight_kg, height_cm)
            
            # Get prediction from ensemble
            body_fat_ml = self._predict_with_ensemble(features, self.body_fat_ensemble)
            
            # Also calculate using traditional methods for validation
            body_fat_traditional = self._calculate_body_fat_enhanced(measurements, age, gender, weight_kg, height_cm)
            
            # Combine ML and traditional methods with weighting
            ml_weight = 0.7  # Trust ML more if we have good features
            traditional_weight = 0.3
            
            combined_body_fat = (body_fat_ml * ml_weight + body_fat_traditional * traditional_weight)
            
            # Apply bounds based on gender and age
            if gender.lower() in ['male', 'm']:
                return max(3.0, min(35.0, combined_body_fat))
            else:
                return max(8.0, min(45.0, combined_body_fat))
                
        except Exception as e:
            logger.error(f"Error calculating enhanced ML body fat: {e}")
            # Fallback to traditional method
            return self._calculate_body_fat_enhanced(measurements, age, gender, weight_kg, height_cm)
    
    def _calculate_muscle_mass_enhanced_ml(self, measurements: Dict[str, float], age: int,
                                         gender: str, weight_kg: float, height_cm: float,
                                         body_fat_percentage: float) -> float:
        """Calculate muscle mass using enhanced ML ensemble with CV features."""
        try:
            # Prepare enhanced feature vector
            features = self._prepare_enhanced_feature_vector(measurements, age, gender, weight_kg, height_cm)
            
            # Get prediction from ensemble
            muscle_mass_ml = self._predict_with_ensemble(features, self.muscle_mass_ensemble)
            
            # Also calculate using traditional methods for validation
            muscle_mass_traditional = self._calculate_muscle_mass_enhanced(
                measurements, age, gender, weight_kg, height_cm, body_fat_percentage
            )
            
            # Combine ML and traditional methods
            ml_weight = 0.7
            traditional_weight = 0.3
            
            combined_muscle_mass = (muscle_mass_ml * ml_weight + muscle_mass_traditional * traditional_weight)
            
            # Apply physiological bounds
            if gender.lower() in ['male', 'm']:
                return max(25.0, min(60.0, combined_muscle_mass))
            else:
                return max(20.0, min(50.0, combined_muscle_mass))
                
        except Exception as e:
            logger.error(f"Error calculating enhanced ML muscle mass: {e}")
            # Fallback to traditional method
            return self._calculate_muscle_mass_enhanced(measurements, age, gender, weight_kg, height_cm, body_fat_percentage)
    
    def _prepare_enhanced_feature_vector(self, measurements: Dict[str, float], age: int,
                                       gender: str, weight_kg: float, height_cm: float) -> np.ndarray:
        """Prepare enhanced feature vector for ML models."""
        try:
            # Basic anthropometric ratios
            waist_to_height = measurements.get('waist_width', 80) / height_cm
            waist_to_hip = measurements.get('waist_width', 80) / measurements.get('hip_width', 95)
            shoulder_to_waist = measurements.get('shoulder_width', 40) / measurements.get('waist_width', 80)
            arm_to_height = measurements.get('left_arm_length', 60) / height_cm
            leg_to_height = measurements.get('left_leg_length', 90) / height_cm
            
            # Enhanced ratios
            neck_to_waist = measurements.get('neck_circumference', 35) / measurements.get('waist_width', 80)
            chest_to_waist = measurements.get('chest_circumference', 90) / measurements.get('waist_width', 80)
            thigh_to_waist = 0.65  # Placeholder - would extract from CV in production
            
            # BMI and body composition proxies
            bmi = weight_kg / ((height_cm / 100) ** 2)
            bmi_normalized = (bmi - 23) / 10  # Normalize around healthy BMI
            
            # Age factor
            age_normalized = (age - 30) / 50  # Normalize around middle age
            
            # Gender encoding
            gender_factor = 1 if gender.lower() in ['male', 'm'] else 0
            
            # Body symmetry (simplified - would be calculated from CV in production)
            body_symmetry = 0.95
            
            # Muscle tone indicator (based on shoulder development and body proportions)
            muscle_tone = (shoulder_to_waist - 1.0) + (1.0 - waist_to_height)
            muscle_tone = np.clip(muscle_tone, 0, 1)
            
            # Construct feature vector
            features = np.array([
                waist_to_height, waist_to_hip, shoulder_to_waist,
                arm_to_height, leg_to_height, body_symmetry,
                neck_to_waist, chest_to_waist, thigh_to_waist,
                bmi_normalized, age_normalized, gender_factor, muscle_tone
            ])
            
            return features
            
        except Exception as e:
            logger.error(f"Error preparing feature vector: {e}")
            # Return default feature vector
            return np.array([0.5, 0.85, 1.3, 0.44, 0.5, 0.95, 0.44, 1.15, 0.65, 0, 0, 1, 0.5])
    
    def _analyze_body_parts_enhanced_cv(self, landmarks, segmentation_mask, 
                                      measurements: Dict[str, float], image: np.ndarray) -> Dict[str, Dict[str, float]]:
        """Enhanced body parts analysis using computer vision and segmentation."""
        body_parts_data = {}
        
        for part_name, landmark_indices in self.body_parts.items():
            try:
                # Enhanced metrics using CV techniques
                part_data = {
                    "circumference_cm": self._estimate_part_circumference_cv(
                        part_name, measurements, landmark_indices, landmarks, segmentation_mask
                    ),
                    "area_percentage": self._calculate_part_area_enhanced_cv(
                        landmark_indices, segmentation_mask, measurements, image
                    ),
                    "muscle_definition": self._calculate_muscle_definition_enhanced_cv(
                        landmark_indices, landmarks, measurements, image
                    ),
                    "fat_distribution": self._calculate_fat_distribution_enhanced_cv(
                        landmark_indices, landmarks, measurements, segmentation_mask
                    ),
                    "symmetry_score": self._calculate_symmetry_enhanced_cv(
                        landmark_indices, landmarks, image
                    ),
                    "texture_analysis": self._analyze_skin_texture(
                        landmark_indices, image, segmentation_mask
                    )
                }
                body_parts_data[part_name] = part_data
                
            except Exception as e:
                logger.error(f"Error analyzing {part_name} with CV: {e}")
                body_parts_data[part_name] = {
                    "circumference_cm": 30.0,
                    "area_percentage": 5.0,
                    "muscle_definition": 0.5,
                    "fat_distribution": 0.5,
                    "symmetry_score": 0.9,
                    "texture_analysis": 0.5
                }
        
        return body_parts_data
    
    def _estimate_part_circumference_cv(self, part_name: str, measurements: Dict[str, float],
                                      landmark_indices: List[int], landmarks, segmentation_mask) -> float:
        """Estimate circumference using computer vision and segmentation."""
        try:
            # Basic circumference estimation
            base_circumference = self._estimate_part_circumference(part_name, measurements, landmark_indices, landmarks)
            
            # Enhance using segmentation data
            if segmentation_mask is not None:
                # Extract the region of interest from segmentation
                mask_region = self._extract_body_part_mask(landmark_indices, landmarks, segmentation_mask)
                
                if mask_region is not None and np.sum(mask_region) > 0:
                    # Calculate area and estimate circumference from area
                    area = np.sum(mask_region)
                    # Assuming roughly circular cross-section
                    radius_estimate = np.sqrt(area / np.pi)
                    circumference_from_area = 2 * np.pi * radius_estimate
                    
                    # Combine with landmark-based estimate
                    combined_circumference = (base_circumference * 0.6 + circumference_from_area * 0.4)
                    return combined_circumference
            
            return base_circumference
            
        except Exception as e:
            logger.error(f"Error estimating circumference for {part_name}: {e}")
            return self._estimate_part_circumference(part_name, measurements, landmark_indices, landmarks)
    
    def _calculate_part_area_enhanced_cv(self, landmark_indices: List[int], 
                                       segmentation_mask, measurements: Dict[str, float], 
                                       image: np.ndarray) -> float:
        """Enhanced area calculation using computer vision."""
        try:
            if segmentation_mask is not None:
                # Extract body part region
                part_mask = self._extract_body_part_mask(landmark_indices, None, segmentation_mask)
                
                if part_mask is not None:
                    # Calculate actual pixel area
                    pixel_area = np.sum(part_mask)
                    total_body_area = np.sum(segmentation_mask > 0.5)
                    
                    if total_body_area > 0:
                        area_percentage = (pixel_area / total_body_area) * 100
                        return min(25.0, max(1.0, area_percentage))
            
            # Fallback to traditional method
            return self._calculate_part_area_enhanced(landmark_indices, segmentation_mask, measurements)
            
        except Exception as e:
            logger.error(f"Error calculating enhanced area: {e}")
            return 5.0
    
    def _calculate_muscle_definition_enhanced_cv(self, landmark_indices: List[int], 
                                               landmarks, measurements: Dict[str, float],
                                               image: np.ndarray) -> float:
        """Enhanced muscle definition using computer vision."""
        try:
            # Basic visibility-based score
            base_score = self._calculate_muscle_definition_enhanced(landmark_indices, landmarks, measurements)
            
            # Enhance with texture analysis
            if len(landmark_indices) >= 2:
                # Extract region around landmarks
                region = self._extract_landmark_region(landmark_indices, landmarks, image)
                
                if region is not None:
                    # Analyze edge density (muscle definition creates more edges)
                    gray_region = cv2.cvtColor(region, cv2.COLOR_RGB2GRAY) if len(region.shape) == 3 else region
                    edges = canny(gray_region, sigma=1.0)
                    edge_density = np.sum(edges) / edges.size
                    
                    # Analyze texture contrast
                    texture_contrast = gray_region.std() / (gray_region.mean() + 1)
                    
                    # Combine metrics
                    cv_score = (edge_density * 0.6 + texture_contrast * 0.4)
                    cv_score = np.clip(cv_score, 0, 1)
                    
                    # Combine with base score
                    combined_score = (base_score * 0.7 + cv_score * 0.3)
                    return np.clip(combined_score, 0, 1)
            
            return base_score
            
        except Exception as e:
            logger.error(f"Error calculating enhanced muscle definition: {e}")
            return 0.5
    
    def _calculate_fat_distribution_enhanced_cv(self, landmark_indices: List[int], 
                                              landmarks, measurements: Dict[str, float],
                                              segmentation_mask) -> float:
        """Enhanced fat distribution using computer vision."""
        try:
            # Basic measurement-based score
            base_score = self._calculate_fat_distribution_enhanced(landmark_indices, landmarks, measurements)
            
            # Enhance with segmentation analysis
            if segmentation_mask is not None:
                # Analyze thickness of body parts using segmentation
                part_mask = self._extract_body_part_mask(landmark_indices, landmarks, segmentation_mask)
                
                if part_mask is not None and np.sum(part_mask) > 0:
                    # Calculate thickness variation (fat creates more thickness variation)
                    thickness_map = self._calculate_thickness_map(part_mask)
                    thickness_variation = np.std(thickness_map) / (np.mean(thickness_map) + 1)
                    
                    # Higher variation suggests more fat distribution
                    cv_score = np.clip(thickness_variation, 0, 1)
                    
                    # Combine with base score
                    combined_score = (base_score * 0.6 + cv_score * 0.4)
                    return np.clip(combined_score, 0, 1)
            
            return base_score
            
        except Exception as e:
            logger.error(f"Error calculating enhanced fat distribution: {e}")
            return 0.5
    
    def _calculate_symmetry_enhanced_cv(self, landmark_indices: List[int], 
                                      landmarks, image: np.ndarray) -> float:
        """Enhanced symmetry calculation using computer vision."""
        try:
            # Basic landmark symmetry
            base_symmetry = self._calculate_symmetry_enhanced(landmark_indices, landmarks)
            
            # Enhance with image analysis
            if len(landmark_indices) >= 2:
                region = self._extract_landmark_region(landmark_indices, landmarks, image)
                
                if region is not None and region.shape[1] > 20:
                    # Split region in half and compare
                    height, width = region.shape[:2]
                    left_half = region[:, :width//2]
                    right_half = region[:, width//2:]
                    
                    # Flip right half for comparison
                    right_half_flipped = np.fliplr(right_half)
                    
                    # Resize to same dimensions if needed
                    if left_half.shape != right_half_flipped.shape:
                        right_half_flipped = cv2.resize(right_half_flipped, 
                                                      (left_half.shape[1], left_half.shape[0]))
                    
                    # Calculate structural similarity
                    if len(left_half.shape) == 3:
                        left_gray = cv2.cvtColor(left_half, cv2.COLOR_RGB2GRAY)
                        right_gray = cv2.cvtColor(right_half_flipped, cv2.COLOR_RGB2GRAY)
                    else:
                        left_gray = left_half
                        right_gray = right_half_flipped
                    
                    # Simple correlation-based similarity
                    correlation = np.corrcoef(left_gray.flatten(), right_gray.flatten())[0, 1]
                    cv_symmetry = max(0, correlation)
                    
                    # Combine with base symmetry
                    combined_symmetry = (base_symmetry * 0.6 + cv_symmetry * 0.4)
                    return np.clip(combined_symmetry, 0, 1)
            
            return base_symmetry
            
        except Exception as e:
            logger.error(f"Error calculating enhanced symmetry: {e}")
            return 0.9
    
    def _analyze_skin_texture(self, landmark_indices: List[int], image: np.ndarray,
                            segmentation_mask) -> float:
        """Analyze skin texture for additional body composition insights."""
        try:
            # Extract skin region
            region = self._extract_landmark_region(landmark_indices, None, image)
            
            if region is not None:
                gray_region = cv2.cvtColor(region, cv2.COLOR_RGB2GRAY) if len(region.shape) == 3 else region
                
                # Calculate texture features
                # Local Binary Pattern-like analysis
                texture_variance = gray_region.std()
                
                # Smoothness (inverse of gradient magnitude)
                grad_x = cv2.Sobel(gray_region, cv2.CV_64F, 1, 0, ksize=3)
                grad_y = cv2.Sobel(gray_region, cv2.CV_64F, 0, 1, ksize=3)
                gradient_magnitude = np.sqrt(grad_x**2 + grad_y**2)
                smoothness = 1.0 / (1.0 + gradient_magnitude.mean())
                
                # Normalize and combine
                texture_score = (texture_variance / 50 + smoothness) / 2
                return np.clip(texture_score, 0, 1)
            
            return 0.5
            
        except Exception as e:
            logger.error(f"Error analyzing skin texture: {e}")
            return 0.5
        """Calculate body fat using enhanced anthropometric methods."""
        try:
            # Get measurements with defaults
            waist_cm = measurements.get('waist_width_cm', measurements.get('waist_width', 80))
            neck_cm = measurements.get('neck_width_cm', measurements.get('neck_circumference', 35))
            hip_cm = measurements.get('hip_width_cm', measurements.get('hip_width', 95))
            
            # Convert pixel measurements to cm if needed
            if waist_cm > 200:  # Likely pixel measurement
                waist_cm = waist_cm * 0.1  # Rough conversion
            if neck_cm > 100:
                neck_cm = neck_cm * 0.1
            if hip_cm > 200:
                hip_cm = hip_cm * 0.1
            
            # Navy Method (most accurate for general population)
            if gender.lower() in ['male', 'm']:
                # Men: 495/(1.0324-0.19077*log10(waist-neck)+0.15456*log10(height))-450
                body_fat_navy = 495 / (1.0324 - 0.19077 * np.log10(waist_cm - neck_cm) + 
                                     0.15456 * np.log10(height_cm)) - 450
            else:
                # Women: 495/(1.29579-0.35004*log10(waist+hip-neck)+0.22100*log10(height))-450
                body_fat_navy = 495 / (1.29579 - 0.35004 * np.log10(waist_cm + hip_cm - neck_cm) + 
                                     0.22100 * np.log10(height_cm)) - 450
            
            # Jackson-Pollock 3-site approximation (using available measurements)
            bmi = weight_kg / ((height_cm / 100) ** 2)
            waist_to_height = waist_cm / height_cm
            
            if gender.lower() in ['male', 'm']:
                # Approximation based on waist-to-height ratio and BMI
                body_fat_jp = (1.20 * bmi) + (0.23 * age) - (10.8 * 1) - 5.4  # 1 for male
                # Adjust based on waist-to-height ratio
                body_fat_jp += (waist_to_height - 0.53) * 50  # Penalty for high waist ratio
            else:
                body_fat_jp = (1.20 * bmi) + (0.23 * age) - (10.8 * 0) - 5.4  # 0 for female
                body_fat_jp += (waist_to_height - 0.49) * 45  # Different threshold for women
            
            # Deurenberg formula (BMI and age based)
            body_fat_deur = (1.2 * bmi) + (0.23 * age) - (10.8 * (1 if gender.lower() in ['male', 'm'] else 0)) - 5.4
            
            # Combine methods with weights based on reliability
            navy_weight = 0.5 if abs(body_fat_navy) < 50 else 0.1  # Navy method most reliable
            jp_weight = 0.3
            deur_weight = 0.2
            
            total_weight = navy_weight + jp_weight + deur_weight
            
            combined_body_fat = (
                (body_fat_navy * navy_weight + 
                 body_fat_jp * jp_weight + 
                 body_fat_deur * deur_weight) / total_weight
            )
            
            # Apply reasonable bounds
            return max(3.0, min(50.0, combined_body_fat))
            
        except Exception as e:
            logger.error(f"Error calculating enhanced body fat: {e}")
            # Fall back to simple BMI-based estimation
            bmi = weight_kg / ((height_cm / 100) ** 2)
            if gender.lower() in ['male', 'm']:
                return max(5, min(35, (1.2 * bmi) + (0.23 * age) - 16.2))
            else:
                return max(5, min(45, (1.2 * bmi) + (0.23 * age) - 5.4))
    
    def _calculate_muscle_mass_enhanced(self, measurements: Dict[str, float], age: int,
                                      gender: str, weight_kg: float, height_cm: float,
                                      body_fat_percentage: float) -> float:
        """Calculate muscle mass using enhanced anthropometric methods."""
        try:
            # Lee et al. equation for skeletal muscle mass
            # SM (kg) = Ht^2 / R + 0.04 * Age + gender_factor + ethnicity_factor
            # Where R is resistance (approximated from body composition)
            
            # Approximate resistance from body fat percentage
            # Lower body fat typically means higher muscle density
            resistance_factor = 400 + (body_fat_percentage * 15)  # Ohms approximation
            
            # Get limb measurements
            arm_circumference = measurements.get('arm_circumference_cm', 
                                               measurements.get('left_arm_length', 60) * 0.4)
            thigh_circumference = measurements.get('thigh_circumference_cm', 
                                                 measurements.get('left_leg_length', 90) * 0.6)
            
            # Convert pixel measurements if needed
            if arm_circumference > 100:
                arm_circumference *= 0.1
            if thigh_circumference > 100:
                thigh_circumference *= 0.1
            
            # Modified Lee equation
            gender_factor = 2.3 if gender.lower() in ['male', 'm'] else -2.3
            
            skeletal_muscle_kg = (
                (height_cm ** 2) / resistance_factor +
                0.04 * age +
                gender_factor +
                (arm_circumference + thigh_circumference) * 0.1  # Limb circumference contribution
            )
            
            # Alternative: James equation using limb circumferences
            # Total muscle mass = skeletal muscle * 1.19 (accounts for cardiac and smooth muscle)
            if arm_circumference > 10 and thigh_circumference > 10:
                # Anthropometric muscle mass estimation
                muscle_area_arm = (arm_circumference ** 2) / (4 * np.pi)
                muscle_area_thigh = (thigh_circumference ** 2) / (4 * np.pi)
                
                # Estimate total muscle mass from limb measurements
                limb_muscle_kg = (muscle_area_arm * 2 + muscle_area_thigh * 2) * 0.015  # Density factor
                total_muscle_kg = limb_muscle_kg * 2.5  # Total body factor
            else:
                total_muscle_kg = skeletal_muscle_kg * 1.19
            
            # Fat-free mass approach
            fat_free_mass = weight_kg * (1 - body_fat_percentage / 100)
            # Muscle mass is approximately 45-50% of fat-free mass
            muscle_from_ffm = fat_free_mass * 0.47
            
            # Combine approaches
            muscle_mass_kg = (total_muscle_kg * 0.4 + muscle_from_ffm * 0.6)
            
            # Convert to percentage
            muscle_percentage = (muscle_mass_kg / weight_kg) * 100
            
            # Apply physiological bounds
            if gender.lower() in ['male', 'm']:
                return max(25.0, min(55.0, muscle_percentage))
            else:
                return max(20.0, min(45.0, muscle_percentage))
            
        except Exception as e:
            logger.error(f"Error calculating enhanced muscle mass: {e}")
            # Fall back to simple estimation
            fat_free_mass = weight_kg * (1 - body_fat_percentage / 100)
            muscle_percentage = (fat_free_mass * 0.45 / weight_kg) * 100
            
            if gender.lower() in ['male', 'm']:
                return max(25.0, min(55.0, muscle_percentage))
            else:
                return max(20.0, min(45.0, muscle_percentage))
    
    def _calculate_body_ratios_enhanced(self, measurements: Dict[str, float]) -> Dict[str, float]:
        """Calculate enhanced body ratios with physical measurements."""
        ratios = {}
        
        try:
            height = measurements.get('height_cm', measurements.get('body_height', 170))
            waist = measurements.get('waist_width_cm', measurements.get('waist_width', 80))
            hip = measurements.get('hip_width_cm', measurements.get('hip_width', 95))
            shoulder = measurements.get('shoulder_width_cm', measurements.get('shoulder_width', 40))
            neck = measurements.get('neck_width_cm', measurements.get('neck_circumference', 35))
            
            # Convert pixel measurements if needed
            if height > 250:  # Likely pixel measurement
                scale = 170 / height  # Assume average height
                height *= scale
                waist *= scale
                hip *= scale
                shoulder *= scale
                neck *= scale
            
            ratios["waist_to_height"] = waist / height
            ratios["waist_to_hip"] = waist / hip
            ratios["shoulder_to_waist"] = shoulder / waist
            ratios["neck_to_waist"] = neck / waist
            ratios["shoulder_to_hip"] = shoulder / hip
            
            # Additional health ratios
            ratios["waist_to_neck"] = waist / neck
            ratios["body_adiposity_index"] = (hip / (height ** 1.5)) - 18  # BAI formula
            
        except Exception as e:
            logger.error(f"Error calculating enhanced ratios: {e}")
            # Default ratios
            ratios = {
                "waist_to_height": 0.5,
                "waist_to_hip": 0.85,
                "shoulder_to_waist": 1.3,
                "neck_to_waist": 0.44,
                "shoulder_to_hip": 1.1,
                "waist_to_neck": 2.3,
                "body_adiposity_index": 15
            }
        
        return ratios
    
    def _estimate_visceral_fat_enhanced(self, measurements: Dict[str, float], 
                                      body_fat: float, age: int, gender: str) -> int:
        """Enhanced visceral fat estimation using multiple factors."""
        try:
            waist_cm = measurements.get('waist_width_cm', measurements.get('waist_width', 80))
            if waist_cm > 200:  # Convert from pixels
                waist_cm *= 0.1
            
            # Waist circumference thresholds
            waist_risk = 0
            if gender.lower() in ['male', 'm']:
                if waist_cm > 102:  # High risk
                    waist_risk = 10
                elif waist_cm > 94:  # Medium risk
                    waist_risk = 5
            else:
                if waist_cm > 88:  # High risk
                    waist_risk = 10
                elif waist_cm > 80:  # Medium risk
                    waist_risk = 5
            
            # Age factor
            age_factor = max(0, (age - 25) * 0.2)
            
            # Body fat factor
            bf_factor = max(0, (body_fat - 20) * 0.5)
            
            visceral_level = 1 + waist_risk + age_factor + bf_factor
            
            return max(1, min(20, int(visceral_level)))
            
        except Exception as e:
            logger.error(f"Error estimating visceral fat: {e}")
            return max(1, min(20, int(body_fat * 0.3 + age * 0.1)))
    
    def _estimate_bmr_enhanced(self, weight_kg: float, height_cm: float, 
                             age: int, gender: str, muscle_mass_percentage: float) -> int:
        """Enhanced BMR calculation using multiple formulas."""
        try:
            # Katch-McArdle Formula (most accurate when body composition is known)
            lean_mass_kg = weight_kg * (muscle_mass_percentage / 100) * 2.1  # Convert muscle to lean mass
            bmr_katch = 370 + (21.6 * lean_mass_kg)
            
            # Mifflin-St Jeor Equation
            if gender.lower() in ['male', 'm']:
                bmr_mifflin = 88.362 + (13.397 * weight_kg) + (4.799 * height_cm) - (5.677 * age)
            else:
                bmr_mifflin = 447.593 + (9.247 * weight_kg) + (3.098 * height_cm) - (4.330 * age)
            
            # Harris-Benedict Equation (revised)
            if gender.lower() in ['male', 'm']:
                bmr_harris = 88.362 + (13.397 * weight_kg) + (4.799 * height_cm) - (5.677 * age)
            else:
                bmr_harris = 447.593 + (9.247 * weight_kg) + (3.098 * height_cm) - (4.330 * age)
            
            # Weight average (Katch-McArdle is most accurate if we have body composition)
            bmr_combined = (bmr_katch * 0.5 + bmr_mifflin * 0.3 + bmr_harris * 0.2)
            
            return max(800, min(3000, int(bmr_combined)))
            
        except Exception as e:
            logger.error(f"Error calculating enhanced BMR: {e}")
            # Fall back to simple Mifflin-St Jeor
            if gender.lower() in ['male', 'm']:
                bmr = 88.362 + (13.397 * weight_kg) + (4.799 * height_cm) - (5.677 * age)
            else:
                bmr = 447.593 + (9.247 * weight_kg) + (3.098 * height_cm) - (4.330 * age)
            return max(800, min(3000, int(bmr)))
    
    def _classify_body_shape_enhanced(self, measurements: Dict[str, float], 
                                    ratios: Dict[str, float]) -> str:
        """Enhanced body shape classification."""
        try:
            shoulder_to_waist = ratios.get("shoulder_to_waist", 1.3)
            waist_to_hip = ratios.get("waist_to_hip", 0.85)
            shoulder_to_hip = ratios.get("shoulder_to_hip", 1.1)
            
            # More detailed classification
            if shoulder_to_waist > 1.45 and waist_to_hip < 0.75:
                return "Athletic V-Shape"
            elif shoulder_to_waist > 1.35 and waist_to_hip < 0.8:
                return "Athletic Build"
            elif shoulder_to_hip > 1.15 and waist_to_hip < 0.85:
                return "Inverted Triangle"
            elif 0.8 <= waist_to_hip <= 0.9 and shoulder_to_hip < 1.15:
                return "Rectangle/Straight"
            elif waist_to_hip > 0.9:
                return "Apple Shape"
            elif shoulder_to_hip < 1.0:
                return "Pear Shape"
            else:
                return "Hourglass"
                
        except Exception as e:
            logger.error(f"Error classifying body shape: {e}")
            return "Average Build"
    
    def _analyze_body_parts_enhanced(self, landmarks, segmentation_mask, 
                                   measurements: Dict[str, float]) -> Dict[str, Dict[str, float]]:
        """Enhanced body parts analysis with physical measurements."""
        body_parts_data = {}
        
        for part_name, landmark_indices in self.body_parts.items():
            try:
                # Calculate enhanced metrics for each body part
                part_data = {
                    "circumference_cm": self._estimate_part_circumference(
                        part_name, measurements, landmark_indices, landmarks
                    ),
                    "area_percentage": self._calculate_part_area_enhanced(
                        landmark_indices, segmentation_mask, measurements
                    ),
                    "muscle_definition": self._calculate_muscle_definition_enhanced(
                        landmark_indices, landmarks, measurements
                    ),
                    "fat_distribution": self._calculate_fat_distribution_enhanced(
                        landmark_indices, landmarks, measurements
                    ),
                    "symmetry_score": self._calculate_symmetry_enhanced(
                        landmark_indices, landmarks
                    )
                }
                body_parts_data[part_name] = part_data
                
            except Exception as e:
                logger.error(f"Error analyzing {part_name}: {e}")
                body_parts_data[part_name] = {
                    "circumference_cm": 30.0,
                    "area_percentage": 5.0,
                    "muscle_definition": 0.5,
                    "fat_distribution": 0.5,
                    "symmetry_score": 0.9
                }
        
        return body_parts_data
    
    def _estimate_part_circumference(self, part_name: str, measurements: Dict[str, float],
                                   landmark_indices: List[int], landmarks) -> float:
        """Estimate circumference of body part."""
        try:
            if part_name == "neck":
                return measurements.get('neck_width_cm', measurements.get('neck_circumference', 35))
            elif part_name == "chest":
                return measurements.get('chest_circumference_cm', 
                                     measurements.get('shoulder_width_cm', 40) * 2.5)
            elif part_name == "waist":
                return measurements.get('waist_width_cm', measurements.get('waist_width', 80))
            elif part_name == "arms":
                return measurements.get('arm_circumference_cm', 30)
            elif part_name == "thighs":
                return measurements.get('thigh_circumference_cm', 55)
            else:
                return 35.0  # Default
        except:
            return 35.0
    
    def _calculate_part_area_enhanced(self, landmark_indices: List[int], 
                                    segmentation_mask, measurements: Dict[str, float]) -> float:
        """Enhanced area calculation using measurements."""
        # Use circumference to estimate area percentage
        try:
            total_body_area = measurements.get('estimated_weight', 70) * 0.3  # Rough body surface area
            # This would be more sophisticated in production
            return np.random.uniform(3, 8)  
        except:
            return 5.0
    
    def _calculate_muscle_definition_enhanced(self, landmark_indices: List[int], 
                                            landmarks, measurements: Dict[str, float]) -> float:
        """Enhanced muscle definition calculation."""
        try:
            # Combine visibility with measurement ratios
            visibility_scores = [landmarks[i].visibility for i in landmark_indices]
            avg_visibility = np.mean(visibility_scores)
            
            # Use body fat percentage to adjust muscle definition
            body_fat_est = measurements.get('estimated_body_fat', 20)
            muscle_factor = max(0.1, 1.0 - (body_fat_est - 10) / 30)  # Higher BF = less definition
            
            return min(1.0, avg_visibility * muscle_factor)
        except:
            return 0.5
    
    def _calculate_fat_distribution_enhanced(self, landmark_indices: List[int], 
                                           landmarks, measurements: Dict[str, float]) -> float:
        """Enhanced fat distribution assessment."""
        try:
            # Use waist-to-hip ratio and other measurements
            waist_to_hip = measurements.get('waist_width', 80) / measurements.get('hip_width', 95)
            
            # Central vs peripheral fat distribution
            if waist_to_hip > 0.9:  # More central fat
                return 0.7
            elif waist_to_hip < 0.8:  # More peripheral fat
                return 0.3
            else:
                return 0.5
        except:
            return 0.5
    
    def _calculate_symmetry_enhanced(self, landmark_indices: List[int], landmarks) -> float:
        """Enhanced symmetry calculation using bilateral landmarks."""
        try:
            # Calculate bilateral symmetry for paired landmarks
            left_landmarks = []
            right_landmarks = []
            
            for idx in landmark_indices:
                if idx in [11, 13, 15, 17, 19, 21, 23, 25, 27]:  # Left side
                    left_landmarks.append(landmarks[idx])
                elif idx in [12, 14, 16, 18, 20, 22, 24, 26, 28]:  # Right side
                    right_landmarks.append(landmarks[idx])
            
            if len(left_landmarks) == len(right_landmarks) and len(left_landmarks) > 0:
                symmetry_scores = []
                for left, right in zip(left_landmarks, right_landmarks):
                    # Calculate distance difference
                    left_pos = np.array([left.x, left.y])
                    right_pos = np.array([right.x, right.y])
                    # Mirror right position and compare
                    right_mirrored = np.array([1.0 - right.x, right.y])
                    symmetry = 1.0 - np.linalg.norm(left_pos - right_mirrored)
                    symmetry_scores.append(max(0, symmetry))
                
                return np.mean(symmetry_scores)
            else:
                return 0.95  # Default high symmetry
        except:
            return 0.9
    
    def _calculate_analysis_confidence_enhanced(self, landmarks, image: np.ndarray, 
                                              physical_measurements: Dict[str, float] = None) -> float:
        """Enhanced confidence calculation considering physical measurements."""
        # Base confidence on landmark visibility and image quality
        visibility_scores = [landmark.visibility for landmark in landmarks]
        avg_visibility = np.mean(visibility_scores)
        
        # Image quality assessment
        gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
        laplacian_var = cv2.Laplacian(gray, cv2.CV_64F).var()
        sharpness_score = min(1.0, laplacian_var / 500)  # Normalize
        
        # Boost confidence if physical measurements are provided
        measurement_boost = 0.0
        if physical_measurements:
            provided_measurements = len([k for k, v in physical_measurements.items() if v is not None and v > 0])
            measurement_boost = min(0.3, provided_measurements * 0.05)  # Up to 30% boost
        
        # Combine factors
        confidence = (avg_visibility * 0.5 + sharpness_score * 0.3 + 0.2) + measurement_boost
        return round(min(1.0, confidence), 2)
    
    def _extract_body_measurements(self, landmarks, width: int, height: int) -> Dict[str, float]:
        """Extract body measurements from pose landmarks."""
        measurements = {}
        
        try:
            # Convert normalized coordinates to pixels
            def get_point(landmark_idx):
                return (landmarks[landmark_idx].x * width, landmarks[landmark_idx].y * height)
            
            # Shoulder width
            left_shoulder = get_point(11)
            right_shoulder = get_point(12)
            measurements["shoulder_width"] = np.linalg.norm(
                np.array(left_shoulder) - np.array(right_shoulder)
            )
            
            # Hip width
            left_hip = get_point(23)
            right_hip = get_point(24)
            measurements["hip_width"] = np.linalg.norm(
                np.array(left_hip) - np.array(right_hip)
            )
            
            # Waist estimation
            measurements["waist_width"] = (measurements["shoulder_width"] + measurements["hip_width"]) / 2
            
            # Body height
            nose = get_point(0)
            left_ankle = get_point(27)
            right_ankle = get_point(28)
            avg_ankle = ((left_ankle[0] + right_ankle[0]) / 2, (left_ankle[1] + right_ankle[1]) / 2)
            measurements["body_height"] = abs(nose[1] - avg_ankle[1])
            
            # Arm length
            left_wrist = get_point(15)
            measurements["left_arm_length"] = np.linalg.norm(
                np.array(left_shoulder) - np.array(left_wrist)
            )
            
            # Leg length
            measurements["left_leg_length"] = np.linalg.norm(
                np.array(left_hip) - np.array(left_ankle)
            )
            
            # Estimate weight based on body dimensions
            body_volume_ratio = (measurements["shoulder_width"] * measurements["hip_width"] * 
                               measurements["body_height"]) / (width * height * height)
            measurements["estimated_weight"] = max(40, min(120, body_volume_ratio * 70000))
            
        except Exception as e:
            logger.error(f"Error extracting measurements: {e}")
            # Default measurements if extraction fails
            measurements = {
                "shoulder_width": width * 0.2,
                "hip_width": width * 0.18,
                "waist_width": width * 0.16,
                "body_height": height * 0.8,
                "left_arm_length": height * 0.35,
                "left_leg_length": height * 0.45,
                "estimated_weight": 70
            }
        
        return measurements
    
    def _calculate_body_ratios(self, measurements: Dict[str, float]) -> Dict[str, float]:
        """Calculate important body ratios for composition analysis."""
        ratios = {}
        
        try:
            ratios["waist_to_height"] = measurements["waist_width"] / measurements["body_height"]
            ratios["waist_to_hip"] = measurements["waist_width"] / measurements["hip_width"]
            ratios["shoulder_to_waist"] = measurements["shoulder_width"] / measurements["waist_width"]
            ratios["arm_to_height"] = measurements["left_arm_length"] / measurements["body_height"]
            ratios["leg_to_height"] = measurements["left_leg_length"] / measurements["body_height"]
            ratios["body_symmetry"] = 0.95  # Simplified - would need bilateral analysis
            
        except Exception as e:
            logger.error(f"Error calculating ratios: {e}")
            # Default ratios
            ratios = {
                "waist_to_height": 0.5,
                "waist_to_hip": 0.85,
                "shoulder_to_waist": 1.3,
                "arm_to_height": 0.44,
                "leg_to_height": 0.5,
                "body_symmetry": 0.95
            }
        
        return ratios
    
    def _estimate_visceral_fat(self, ratios: Dict[str, float], body_fat: float) -> int:
        """Estimate visceral fat level (1-20 scale)."""
        waist_to_height = ratios.get("waist_to_height", 0.5)
        
        # Simplified estimation based on waist-to-height ratio and body fat
        visceral_estimate = (waist_to_height - 0.4) * 30 + body_fat * 0.3
        return max(1, min(20, int(visceral_estimate)))
    
    def _estimate_bmr(self, measurements: Dict[str, float], body_fat: float, 
                     muscle_mass: float) -> int:
        """Estimate Basal Metabolic Rate."""
        weight = measurements.get("estimated_weight", 70)
        
        # Katch-McArdle Formula (using lean body mass)
        lean_mass = weight * (muscle_mass / 100)
        bmr = 370 + (21.6 * lean_mass)
        
        return int(bmr)
    
    def _classify_body_shape(self, ratios: Dict[str, float]) -> str:
        """Classify body shape based on ratios."""
        shoulder_to_waist = ratios.get("shoulder_to_waist", 1.3)
        waist_to_hip = ratios.get("waist_to_hip", 0.85)
        
        if shoulder_to_waist > 1.4 and waist_to_hip < 0.8:
            return "Athletic/V-shape"
        elif shoulder_to_waist > 1.3 and waist_to_hip < 0.85:
            return "Inverted Triangle"
        elif 0.85 <= waist_to_hip <= 0.95:
            return "Rectangle"
        elif waist_to_hip > 0.95:
            return "Apple"
        else:
            return "Pear"
    
    def _analyze_body_parts(self, landmarks, segmentation_mask) -> Dict[str, Dict[str, float]]:
        """Analyze individual body parts."""
        body_parts_data = {}
        
        for part_name, landmark_indices in self.body_parts.items():
            try:
                # Calculate area and muscle definition for each body part
                part_data = {
                    "area_percentage": self._calculate_part_area(landmark_indices, segmentation_mask),
                    "muscle_definition": self._calculate_muscle_definition(landmark_indices, landmarks),
                    "fat_distribution": self._calculate_fat_distribution(landmark_indices, landmarks),
                    "symmetry_score": self._calculate_symmetry(landmark_indices, landmarks)
                }
                body_parts_data[part_name] = part_data
                
            except Exception as e:
                logger.error(f"Error analyzing {part_name}: {e}")
                body_parts_data[part_name] = {
                    "area_percentage": 5.0,
                    "muscle_definition": 0.5,
                    "fat_distribution": 0.5,
                    "symmetry_score": 0.9
                }
        
        return body_parts_data
    
    def _calculate_part_area(self, landmark_indices: List[int], 
                           segmentation_mask) -> float:
        """Calculate relative area of body part."""
        # Simplified area calculation
        return np.random.uniform(3, 8)  # Placeholder
    
    def _calculate_muscle_definition(self, landmark_indices: List[int], 
                                   landmarks) -> float:
        """Calculate muscle definition score (0-1)."""
        # Simplified muscle definition based on landmark visibility
        visibility_scores = [landmarks[i].visibility for i in landmark_indices]
        return np.mean(visibility_scores)
    
    def _calculate_fat_distribution(self, landmark_indices: List[int], 
                                  landmarks) -> float:
        """Calculate fat distribution score (0-1)."""
        # Simplified fat distribution assessment
        return np.random.uniform(0.3, 0.8)  # Placeholder
    
    def _calculate_symmetry(self, landmark_indices: List[int], landmarks) -> float:
        """Calculate body part symmetry score (0-1)."""
        # Simplified symmetry calculation
        return np.random.uniform(0.85, 0.98)  # Placeholder
    
    def _calculate_analysis_confidence(self, landmarks, image: np.ndarray) -> float:
        """Calculate confidence score for the analysis."""
        # Base confidence on landmark visibility and image quality
        visibility_scores = [landmark.visibility for landmark in landmarks]
        avg_visibility = np.mean(visibility_scores)
        
        # Image quality assessment (simplified)
        gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
        laplacian_var = cv2.Laplacian(gray, cv2.CV_64F).var()
        sharpness_score = min(1.0, laplacian_var / 500)  # Normalize
        
        # Combine factors
        confidence = (avg_visibility * 0.6 + sharpness_score * 0.4)
        return round(confidence, 2)
    
    def _create_processed_image(self, image: np.ndarray, pose_results, 
                              analysis_results: Dict[str, Any], 
                              original_path: str) -> str:
        """Create annotated image with analysis results."""
        try:
            # Create output directory
            output_dir = Path("processed_images")
            output_dir.mkdir(exist_ok=True)
            
            # Create filename
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"body_analysis_{timestamp}.jpg"
            output_path = output_dir / filename
            
            # Draw pose landmarks
            annotated_image = image.copy()
            mp.solutions.drawing_utils.draw_landmarks(
                annotated_image, 
                pose_results.pose_landmarks,
                mp.solutions.pose.POSE_CONNECTIONS
            )
            
            # Add analysis text
            font = cv2.FONT_HERSHEY_SIMPLEX
            y_offset = 30
            
            analysis_text = [
                f"Body Fat: {analysis_results['body_fat_percentage']}%",
                f"Muscle Mass: {analysis_results['muscle_mass_percentage']}%",
                f"Body Shape: {analysis_results['body_shape']}",
                f"BMR: {analysis_results['bmr_estimated']} cal/day",
                f"Confidence: {analysis_results['confidence']:.2f}"
            ]
            
            for i, text in enumerate(analysis_text):
                cv2.putText(annotated_image, text, (10, y_offset + i * 25), 
                          font, 0.6, (0, 255, 0), 2)
            
            # Save processed image
            cv2.imwrite(str(output_path), annotated_image)
            
            return str(output_path)
            
        except Exception as e:
            logger.error(f"Error creating processed image: {e}")
            return ""
    
    def _save_body_part_measurements(self, analysis_id: str, 
                                   body_parts_data: Dict[str, Dict[str, float]]):
        """Save individual body part measurements."""
        for part_name, part_data in body_parts_data.items():
            measurement_id = hashlib.md5(
                f"{analysis_id}_{part_name}".encode()
            ).hexdigest()
            
            measurement = BodyPartMeasurement(
                measurement_id=measurement_id,
                analysis_id=analysis_id,
                body_part=part_name,
                circumference_cm=0.0,
                area_percentage=part_data["area_percentage"],
                muscle_definition_score=part_data["muscle_definition"],
                fat_distribution_score=part_data["fat_distribution"],
                symmetry_score=part_data["symmetry_score"]
            )
            
            self.db.save_body_part_measurement(measurement)
    
    def _extract_body_part_mask(self, landmark_indices: List[int], landmarks, 
                              segmentation_mask) -> Optional[np.ndarray]:
        """Extract mask for specific body part."""
        try:
            if segmentation_mask is None:
                return None
                
            height, width = segmentation_mask.shape
            mask = np.zeros((height, width), dtype=np.uint8)
            
            if landmarks is not None and len(landmark_indices) >= 2:
                # Create bounding box around landmarks
                points = []
                for idx in landmark_indices:
                    if idx < len(landmarks):
                        x = int(landmarks[idx].x * width)
                        y = int(landmarks[idx].y * height)
                        points.append([x, y])
                
                if len(points) >= 2:
                    points = np.array(points)
                    # Create convex hull around points
                    hull = cv2.convexHull(points)
                    cv2.fillPoly(mask, [hull], 255)
                    
                    # Intersect with segmentation mask
                    body_mask = (segmentation_mask > 0.5).astype(np.uint8) * 255
                    result_mask = cv2.bitwise_and(mask, body_mask)
                    
                    return result_mask
            
            return None
            
        except Exception as e:
            logger.error(f"Error extracting body part mask: {e}")
            return None
    
    def _extract_landmark_region(self, landmark_indices: List[int], landmarks, 
                               image: np.ndarray, padding: int = 20) -> Optional[np.ndarray]:
        """Extract image region around landmarks."""
        try:
            if landmarks is None or len(landmark_indices) < 1:
                return None
                
            height, width = image.shape[:2]
            
            # Get bounding box of landmarks
            min_x, min_y = width, height
            max_x, max_y = 0, 0
            
            for idx in landmark_indices:
                if idx < len(landmarks):
                    x = int(landmarks[idx].x * width)
                    y = int(landmarks[idx].y * height)
                    min_x = min(min_x, x)
                    max_x = max(max_x, x)
                    min_y = min(min_y, y)
                    max_y = max(max_y, y)
            
            # Add padding
            min_x = max(0, min_x - padding)
            min_y = max(0, min_y - padding)
            max_x = min(width, max_x + padding)
            max_y = min(height, max_y + padding)
            
            # Extract region
            if max_x > min_x and max_y > min_y:
                region = image[min_y:max_y, min_x:max_x]
                return region
            
            return None
            
        except Exception as e:
            logger.error(f"Error extracting landmark region: {e}")
            return None
    
    def _calculate_thickness_map(self, mask: np.ndarray) -> np.ndarray:
        """Calculate thickness map of body part using distance transform."""
        try:
            # Apply distance transform to get thickness
            dist_transform = cv2.distanceTransform(mask, cv2.DIST_L2, 5)
            
            # Normalize
            if dist_transform.max() > 0:
                thickness_map = dist_transform / dist_transform.max()
            else:
                thickness_map = dist_transform
                
            return thickness_map
            
        except Exception as e:
            logger.error(f"Error calculating thickness map: {e}")
            return np.zeros_like(mask, dtype=np.float32)
    
    def _estimate_measurement_accuracy(self, measurements: Dict[str, float], landmarks) -> float:
        """Estimate accuracy of extracted measurements."""
        try:
            # Base accuracy on landmark visibility
            visibility_scores = [lm.visibility for lm in landmarks]
            avg_visibility = np.mean(visibility_scores)
            
            # Check measurement consistency
            consistency_score = 1.0
            
            # Check if measurements are reasonable
            if 'shoulder_width' in measurements and 'hip_width' in measurements:
                ratio = measurements['shoulder_width'] / measurements['hip_width']
                if 0.5 <= ratio <= 2.0:  # Reasonable ratio
                    consistency_score *= 1.0
                else:
                    consistency_score *= 0.8
            
            # Check height consistency
            if 'body_height' in measurements and 'left_leg_length' in measurements:
                leg_ratio = measurements['left_leg_length'] / measurements['body_height']
                if 0.3 <= leg_ratio <= 0.6:  # Reasonable leg-to-height ratio
                    consistency_score *= 1.0
                else:
                    consistency_score *= 0.9
            
            # Combine scores
            accuracy = (avg_visibility * 0.7 + consistency_score * 0.3)
            return np.clip(accuracy, 0, 1)
            
        except Exception as e:
            logger.error(f"Error estimating measurement accuracy: {e}")
            return 0.5
    
    def _calculate_analysis_confidence_comprehensive(self, landmarks, image: np.ndarray, 
                                                   physical_measurements: Dict[str, float] = None,
                                                   additional_analysis: Dict[str, Any] = None) -> float:
        """Comprehensive confidence calculation with multiple factors."""
        try:
            # Base confidence components
            visibility_scores = [landmark.visibility for landmark in landmarks]
            avg_visibility = np.mean(visibility_scores)
            
            # Image quality
            image_quality = self._assess_image_quality(image)
            
            # Measurement accuracy
            measurements = self._extract_enhanced_body_measurements(landmarks, image.shape[1], image.shape[0])
            measurement_accuracy = self._estimate_measurement_accuracy(measurements, landmarks)
            
            # Physical measurements boost
            measurement_boost = 0.0
            if physical_measurements:
                provided_count = len([k for k, v in physical_measurements.items() if v is not None and v > 0])
                measurement_boost = min(0.25, provided_count * 0.04)
            
            # Multi-view boost
            multi_view_boost = 0.0
            if additional_analysis and len(additional_analysis) > 0:
                multi_view_boost = min(0.15, len(additional_analysis) * 0.05)
            
            # Pose completeness (how many key landmarks are visible)
            key_landmarks = [0, 11, 12, 23, 24, 15, 16, 27, 28]  # Critical landmarks
            visible_key_landmarks = sum(1 for idx in key_landmarks if landmarks[idx].visibility > 0.5)
            pose_completeness = visible_key_landmarks / len(key_landmarks)
            
            # Combine all factors
            base_confidence = (
                avg_visibility * 0.25 +
                image_quality * 0.20 +
                measurement_accuracy * 0.20 +
                pose_completeness * 0.25 +
                0.10  # Base confidence
            )
            
            # Apply boosts
            total_confidence = base_confidence + measurement_boost + multi_view_boost
            
            return round(min(1.0, total_confidence), 2)
            
        except Exception as e:
            logger.error(f"Error calculating comprehensive confidence: {e}")
            return 0.5
    
    def _create_enhanced_processed_image(self, image: np.ndarray, pose_results, 
                                       analysis_results: Dict[str, Any], 
                                       original_path: str) -> str:
        """Create enhanced annotated image with detailed analysis results."""
        try:
            # Create output directory
            output_dir = Path("processed_images")
            output_dir.mkdir(exist_ok=True)
            
            # Create filename
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"enhanced_body_analysis_{timestamp}.jpg"
            output_path = output_dir / filename
            
            # Create enhanced visualization
            annotated_image = image.copy()
            
            # Draw pose landmarks with enhanced visualization
            if pose_results.pose_landmarks:
                mp.solutions.drawing_utils.draw_landmarks(
                    annotated_image, 
                    pose_results.pose_landmarks,
                    mp.solutions.pose.POSE_CONNECTIONS,
                    mp.solutions.drawing_utils.DrawingSpec(color=(0, 255, 0), thickness=2),
                    mp.solutions.drawing_utils.DrawingSpec(color=(0, 0, 255), thickness=2)
                )
            
            # Add comprehensive analysis text with better formatting
            font = cv2.FONT_HERSHEY_SIMPLEX
            font_scale = 0.7
            thickness = 2
            
            # Create semi-transparent overlay for text
            overlay = annotated_image.copy()
            cv2.rectangle(overlay, (10, 10), (400, 300), (0, 0, 0), -1)
            cv2.addWeighted(overlay, 0.7, annotated_image, 0.3, 0, annotated_image)
            
            analysis_text = [
                f"Enhanced CV Analysis Results:",
                f"Body Fat: {analysis_results['body_fat_percentage']}%",
                f"Muscle Mass: {analysis_results['muscle_mass_percentage']}%",
                f"Body Shape: {analysis_results['body_shape']}",
                f"BMR: {analysis_results['bmr_estimated']} cal/day",
                f"Visceral Fat Level: {analysis_results['visceral_fat_level']}/20",
                f"",
                f"Quality Metrics:",
                f"Confidence: {analysis_results['confidence']:.2f}",
                f"Image Quality: {analysis_results.get('quality_metrics', {}).get('image_quality', 0.5):.2f}",
                f"Pose Confidence: {analysis_results.get('quality_metrics', {}).get('pose_detection_confidence', 0.5):.2f}",
                f"Method: Enhanced CV Pipeline"
            ]
            
            y_offset = 35
            for i, text in enumerate(analysis_text):
                color = (0, 255, 0) if not text.startswith("Quality") and text else (255, 255, 255)
                if text.startswith("Enhanced CV") or text.startswith("Quality"):
                    color = (0, 255, 255)  # Yellow for headers
                
                cv2.putText(annotated_image, text, (15, y_offset + i * 22), 
                          font, font_scale - 0.1, color, thickness - 1)
            
            # Save enhanced processed image
            cv2.imwrite(str(output_path), annotated_image)
            
            return str(output_path)
            
        except Exception as e:
            logger.error(f"Error creating enhanced processed image: {e}")
            return ""


# Singleton instance
_analyzer_instance = None

def get_body_analyzer() -> BodyCompositionAnalyzer:
    """Get singleton body composition analyzer instance."""
    global _analyzer_instance
    if _analyzer_instance is None:
        _analyzer_instance = BodyCompositionAnalyzer()
    return _analyzer_instance
